# Explainable AI for Glaucoma Detection and Classification: A Comprehensive Review

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Paper](https://img.shields.io/badge/Paper-PDF-red.svg)](link-to-paper)
[![DOI](https://img.shields.io/badge/DOI-10.xxxx-green.svg)](https://doi.org/xxx)
[![Studies](https://img.shields.io/badge/Studies-100-brightgreen.svg)]()
[![Coverage](https://img.shields.io/badge/Coverage-2016--2025-orange.svg)]()

> **A PRISMA/PICOS-guided systematic review synthesizing 100 studies on AI-based glaucoma detection, staging, and progression monitoring using multimodal retinal imaging.**

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Global Statistics](#global-statistics)
- [Research Questions](#research-questions)
- [Imaging Modalities](#imaging-modalities)
- [Dataset Resources](#dataset-resources)
- [AI Model Families](#ai-model-families)
- [Performance Benchmarks](#performance-benchmarks)
- [Research Gaps](#research-gaps)
- [Clinical Workflow](#clinical-workflow)
- [Citation](#citation)
- [Authors](#authors)

---

## ğŸ”¬ Overview

Glaucoma is the **leading cause of irreversible blindness** worldwide, progressing silently until substantial optic nerve damage occurs. This comprehensive review evaluates artificial intelligence approaches for:

- âœ… **Detection**: Binary classification (healthy vs. glaucoma)
- âœ… **Staging**: Multi-class severity grading (normal, early, moderate, advanced)
- âœ… **Progression**: Longitudinal monitoring and prediction

### Key Findings

| Aspect | Finding |
|--------|---------|
| **Accuracy** | AI systems achieve **95-99%** accuracy, meeting/exceeding expert performance |
| **Modalities** | **~45%** use CFP, **55-60%** use OCT, **10-15%** use OCTA, **~25%** multimodal |
| **Challenges** | Single-center datasets, vendor lock-in, limited prospective validation |
| **XAI** | Heterogeneous explainability methods (Grad-CAM, SHAP) not aligned to clinical reasoning |

---

## ğŸŒ Global Statistics

### Prevalence by Region (Projected 2040)

| Region | Percentage | Key Insights |
|--------|-----------|--------------|
| **Asia** | 67% | Highest burden globally |
| **Africa** | 19% | Lowest awareness and treatment coverage |
| **Latin America** | 13% | Moderate prevalence |
| **Europe** | 7.85% | High treatment coverage |
| **North America** | 4.72% | High awareness (65%), treatment (60%) |
| **Oceania** | <1% | Smallest population impact |

### Prevalence by Country
### Age-Stratified Risk

- **40-49 years**: 2-3% prevalence
- **50-59 years**: 4-6% prevalence
- **60-69 years**: 7-9% prevalence
- **70-79 years**: 10-12% prevalence
- **80+ years**: 11-15% prevalence (Ghana: 14.6%, Japan: 13.1%)

### Gender Disparity

| Country | Male | Female | Difference |
|---------|------|--------|-----------|
| Ghana | 7.7% | 6.1% | +1.6% |
| Japan | 5.8% | 4.4% | +1.4% |
| USA | 4.2% | 3.6% | +0.6% |

> **Note**: Males show slightly higher risk across most regions

---

## ğŸ¯ Research Questions

This review addresses the following key questions:

### 1. Multimodal Integration
**Q**: How can multimodal imaging approaches (OCT + OCTA + Fundus) improve glaucoma detection compared to single-modality strategies?

**A**: Studies demonstrate **5-12% improvement** in AUC when combining modalities with clinical data (IOP, VF, CCT).

### 2. Structure-Function Correlation
**Q**: How reliable are structural biomarkers (RNFL thickness) in predicting functional outcomes (visual field loss)?

**A**: AI enhances correlation (r=0.832) but requires multimodal integration for optimal prediction.

### 3. Dataset Limitations
**Q**: What strategies overcome small or single-center dataset limitations?

**A**: Transfer learning, data augmentation, federated learning, and multi-center collaboration.

### 4. Early Detection
**Q**: What is the comparative diagnostic value of fundus photography vs. OCT?

**A**: OCT superior for early detection; fundus photography better for population screening.

### 5. Clinical Integration
**Q**: How can AI address the "black box" nature and enhance explainability?

**A**: XAI techniques (SHAP, Grad-CAM, attention mechanisms) with clinical validation needed.

### 6. Global Health Equity
**Q**: How can AI reduce global disparities in glaucoma blindness?

**A**: Lightweight models for mobile/tele-ophthalmology in low-resource settings.

---

## ğŸ–¼ï¸ Imaging Modalities

### 1. Color Fundus Photography (CFP)

**Description**: Magnified, flattened 2D image of optic nerve head and retina

**Key Features**:
- Cup-to-disc ratio (CDR)
- Neuroretinal rim thinning
- RNFL defects
- Disc hemorrhages

**Advantages**:
- âœ… Widely available
- âœ… Low cost
- âœ… Non-invasive
- âœ… Good for population screening

**Limitations**:
- âŒ 2D imaging (depth information lost)
- âŒ Subjective interpretation
- âŒ Image quality variability

### 2. Optical Coherence Tomography (OCT)

**Description**: Cross-sectional 3D imaging with quantitative measurements

**Key Features**:
- RNFL thickness (Âµm)
- Ganglion cell complex (GCC)
- Optic nerve head morphology
- Lamina cribrosa depth

**Advantages**:
- âœ… Quantitative biomarkers
- âœ… Detects early damage
- âœ… High resolution
- âœ… Reproducible

**Limitations**:
- âŒ Higher cost
- âŒ Requires skilled technician
- âŒ Device-specific parameters

### 3. OCT Angiography (OCTA)

**Description**: Non-invasive vascular imaging without dye injection

**Key Features**:
- Vessel density (%)
- Peripapillary capillary dropout
- Macular perfusion
- Radial peripapillary capillaries (RPC)

**Advantages**:
- âœ… Reveals microvascular changes
- âœ… No dye injection
- âœ… High resolution
- âœ… Detects early vascular damage

**Limitations**:
- âŒ Motion artifacts
- âŒ Segmentation errors
- âŒ Limited clinical validation

---

## ğŸ“š Dataset Resources

### Public Datasets for Glaucoma Research

| Dataset | Modality | Images | Classes | Link |
|---------|----------|--------|---------|------|
| **GAMMA** | Fundus + OCT | 4,282 fundus<br>2,262 OCT | Normal, Early,<br>Moderate, Advanced | [Figshare](https://doi.org/10.6084/m9.figshare.c.6406319.v1) |
| **REFUGE** | Fundus | 1,200 | Healthy vs. Glaucoma | [Figshare](https://doi.org/10.6084/m9.figshare.20123135.v2) |
| **Drishti-GS** | Fundus | 101 | Healthy vs. Glaucoma | [Figshare](https://doi.org/10.6084/m9.figshare.14798004.v1) |
| **RIGA** | Fundus | 750 | Healthy vs. Glaucoma | [Deep Blue](https://deepblue.lib.umich.edu/data/concern/data_sets/3b591005z) |
| **G1020** | Fundus | 1,020 | Healthy vs. Glaucoma | [Kaggle](https://www.kaggle.com/datasets) |
| **LAG** | Fundus | 4,503 | Healthy vs. Glaucoma | [Mendeley](https://data.mendeley.com/datasets/2rmz5nz74/2) |
| **ACRIMA** | Fundus + VF | 705 | Healthy vs. Glaucoma | [Figshare](https://figshare.com/s/c2d31f850af14c5232) |
| **AIROGS** | Fundus | 113,893 | Referable vs. Non-referable | [AIROGS Challenge](https://airogs.grand-challenge.org/?utm_source=chatgpt.com) |
| **RIM-ONE v3** | Fundus | 159 | Healthy vs. Glaucoma | [Multiple Sources](https://doi.org/10.6084/m9.figshare.7613135.v1) |
| **ORIGA** | Fundus | 650 | Healthy vs. Glaucoma | [Various](https://doi.org/10.6084/m9.figshare.20123135.v2) |
| **JustRAIGS** | Fundus | 101,423 | Referable vs.<br>Non-referable | [Challenge](https://doi.org/10.6084/m9.figshare.c.6406319.v1) |
| **GHTnet** | Fundus | 1,074 | Healthy vs. Glaucoma | [BMC Article](https://bmcmedimaging.biomedcentral.com/articles/10.1186/s12880-022-00933-z#MOESM1) |

### Dataset Characteristics
```python
# Distribution by imaging modality
Fundus Photography: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 75%
OCT:                â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          45%
OCTA:               â–ˆâ–ˆâ–ˆâ–ˆ                     12%
Multimodal:         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 25%
Visual Field:       â–ˆâ–ˆâ–ˆ                      10%

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AI Models for Glaucoma Detection      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   CNN/DL     â”‚  â”‚     VGG      â”‚           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚  â”‚ U-Net (100%) â”‚  â”‚ VGG16 (93%)  â”‚           â”‚
â”‚  â”‚ ResNet (98%) â”‚  â”‚ VGG19 (99%)  â”‚           â”‚
â”‚  â”‚ DenseNet     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚  â”‚ EfficientNet â”‚                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Transformer  â”‚  â”‚ Random Forestâ”‚           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚  â”‚ ViT (96%)    â”‚  â”‚ RF (98%)     â”‚           â”‚
â”‚  â”‚ DETR (90%)   â”‚  â”‚ XGBoost      â”‚           â”‚
â”‚  â”‚ Swin Trans.  â”‚  â”‚ SVM          â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Hybrid AI   â”‚  â”‚  Clustering  â”‚           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚  â”‚ CNN+RF (93%) â”‚  â”‚ K-Means      â”‚           â”‚
â”‚  â”‚ Transformer- â”‚  â”‚ Hierarchical â”‚           â”‚
â”‚  â”‚ GRU (89%)    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Issue: Models trained on small or single-center datasets
Impact: Poor external validity and generalization
Examples:
  - 60% of studies use <1,000 images
  - 75% single-center data
  - Limited ethnic diversity
Issue: Over-reliance on fundus photography alone
Impact: Missing complementary structural/functional data
Statistics:
  - 45% use only CFP
  - Only 25% truly multimodal
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patient Presents â†’ Medical History â†’ Eye Exam        â”‚
â”‚         â†“                                              â”‚
â”‚  IOP Measurement â†’ OCT/Fundus Imaging â†’ VF Testing    â”‚
â”‚         â†“                                              â”‚
â”‚  Clinician Review â†’ Diagnosis â†’ Treatment Plan        â”‚
â”‚         â†“                                              â”‚
â”‚  Monitoring & Follow-up (3-12 months)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â±ï¸ Time: 60-90 minutes per patient
ğŸ‘¤ Personnel: Ophthalmologist + Technician
ğŸ’° Cost: High (multiple tests, specialist time)
Publication Trend (2016-2025):

2016: â–ˆ 1
2017: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 8
2018: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 10
2019: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 12
2020: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 6
2021: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 16 (Peak)
2022: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 11
2023: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 13
2024: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 9
2025: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 14
